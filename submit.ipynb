{
   "cells":[
      {
         "metadata":{
            "_uuid":"b2a4ab4f-2ad1-46f7-a40e-f772551874fd",
            "_cell_guid":"be244c79-588d-4b43-8e9e-64b59fcf7689",
            "trusted":true
         },
         "cell_type":"code",
         "source":"# %% [code]\n\nimport numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\n\nimport optuna\nfrom optuna.samplers import TPESampler\n\nimport gc\nfrom sklearn.model_selection import train_test_split\nimport riiideducation\n\nkaggle=True\n\n# %% [markdown]\n# # Load data from local dir\n\n# %% [code]\n\n\nif kaggle:\n    import riiideducation\n    env = riiideducation.make_env()\n    train_location = '/kaggle/input/riiid-test-answer-prediction/train.csv'\n    question_location = '/kaggle/input/riiid-test-answer-prediction/questions.csv'\nelse:\n    train_location = 'data/train.csv'\n    question_location = 'data/questions.csv'\n\n# %% [markdown]\n# # Load data from kaggle dir\n\n# %% [code]\nused_data_types_dict = {\n    'timestamp': 'int64',\n    'user_id': 'int32',\n    'content_id': 'int16',\n    'answered_correctly': 'int8',\n    'prior_question_elapsed_time': 'float16',\n    'prior_question_had_explanation': 'boolean'\n}\n\n# %% [code]\n\ntrain_df = pd.read_csv(\n    train_location,\n    usecols = used_data_types_dict.keys(),\n    dtype=used_data_types_dict, \n    index_col = 0\n)\n\n# %% [code]\ntrain_df = train_df[train_df['answered_correctly']!=-1]\n\n# %% [code]\nquestion_df = pd.read_csv(question_location)\n\n# %% [code]\n\ngrouped_by_user_df = train_df.groupby('user_id')\nuser_answers_df = grouped_by_user_df.agg({'answered_correctly': ['mean', 'count', 'std', 'median', 'skew']}).copy()\nuser_answers_df.columns = ['mean_user_accuracy', 'questions_answered', 'std_user_accuracy', 'median_user_accuracy', 'skew_user_accuracy']\nuser_answers_df[\"questions_answered\"]=user_answers_df[\"questions_answered\"].astype('int16')\nuser_answers_df[[\"mean_user_accuracy\",\"std_user_accuracy\",\"skew_user_accuracy\"]]=user_answers_df[[\"mean_user_accuracy\",\"std_user_accuracy\",\"skew_user_accuracy\"]].astype('float32')\nuser_answers_df[\"median_user_accuracy\"]=user_answers_df[\"median_user_accuracy\"].astype('int_')\nprint(user_answers_df.dtypes)\nuser_answers_df\n\n# %% [code]\ndel grouped_by_user_df\ngc.collect()\n\n# %% [code]\ngrouped_by_content_df = train_df.groupby('content_id')\ncontent_answers_df = grouped_by_content_df.agg({'answered_correctly': ['mean', 'count', 'std', 'median', 'skew'] }).copy()\ncontent_answers_df.columns = ['mean_accuracy', 'question_asked', 'std_accuracy', 'median_accuracy', 'skew_accuracy']\ncontent_answers_df[\"question_asked\"]=content_answers_df[\"question_asked\"].astype('int32')\ncontent_answers_df[[\"mean_accuracy\",\"std_accuracy\",\"skew_accuracy\"]]=content_answers_df[[\"mean_accuracy\",\"std_accuracy\",\"skew_accuracy\"]].astype('float32')\ncontent_answers_df[\"median_accuracy\"]=content_answers_df[\"median_accuracy\"].astype('int_')\ncontent_answers_df\n\n# %% [code]\ndel grouped_by_content_df\ngc.collect()\n\n# %% [code]\ntrain_df = train_df.merge(user_answers_df, how='left', on='user_id')\ngc.collect()\n\n# %% [code]\ntrain_df.info(verbose=False, memory_usage=\"deep\")\nquestion_df.info(verbose=False, memory_usage=\"deep\")\nuser_answers_df.info(verbose=False, memory_usage=\"deep\")\ncontent_answers_df.info(verbose=False, memory_usage=\"deep\")\n\n# %% [code]\ngc.collect(0)\n\n# %% [code]\ntrain_df = train_df.merge(content_answers_df, how='left', on='content_id')\ngc.collect()\n\n# %% [code]\nprint('Part of missing values for every column')\nprint(train_df.isnull().sum() / len(train_df))\n\n# %% [code]\ntrain_df['prior_question_had_explanation'] = train_df['prior_question_had_explanation'].fillna(value=False).astype(bool)\ntrain_df = train_df.fillna(value = 0.5)\n\n\ntrain_df = train_df.replace([np.inf, -np.inf], np.nan)\ntrain_df = train_df.fillna(0.5)\n\n# %% [code]\nprint('Part of missing values for every column')\nprint(train_df.isnull().sum() / len(train_df))\n\n# %% [code]\nfor col in train_df.columns:\n    train_df[col] = pd.to_numeric(train_df[col], downcast='integer')\ngc.collect(0)\n\n# %% [code]\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import svm\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import linear_model\n#regressor = RandomForestRegressor(n_estimators=5, max_depth=5, random_state=0)\nregressor = linear_model.LinearRegression()\n#regressor = linear_model.Ridge(alpha=.5)\nXcol = [\n    'mean_user_accuracy', \n    'questions_answered',\n    'std_user_accuracy', \n    'median_user_accuracy',\n    'skew_user_accuracy',\n    'mean_accuracy', \n    'question_asked',\n    'std_accuracy', \n    'median_accuracy',\n    'prior_question_elapsed_time', \n    'prior_question_had_explanation',\n    'skew_accuracy'\n]\ntarget = 'answered_correctly'\n\n# %% [code]\ntrain_df = train_df[Xcol+[target]]\n\n# %% [code]\ntrain_df.info( memory_usage=\"deep\")\n\n\nfor dtype in ['float','int','object']:\n    selected_dtype = train_df.select_dtypes(include=[dtype])\n    mean_usage_b = selected_dtype.memory_usage(deep=True).mean()\n    sum_usage_b = selected_dtype.memory_usage(deep=True).sum()\n    mean_usage_mb = mean_usage_b / 1024 ** 2\n    sum_usage_b = sum_usage_b / 1024 ** 2\n    print(\"Average memory usage for {} columns: {:03.2f} MB, sum is {}\".format(dtype,mean_usage_mb,sum_usage_b))\n\n# %% [code]\ngc.collect()\n\n# %% [code]\n#X_train, X_test, y_train, y_test = train_test_split(train_df[Xcol], train_df[target], test_size=0.1, random_state=0)\n\n\n\nfeatures_df = train_df.iloc[:int(9 /10 * len(train_df))]\ntrain_df = train_df.iloc[int(9 /10 * len(train_df)):]\n\n# %% [code]\n\n\ntrain_df = train_df.replace([np.inf, -np.inf], np.nan)\ntrain_df = train_df.fillna(0.5)\n\n# %% [code]\nregressor.fit(train_df[Xcol], train_df[target])\n\n# %% [code]\ny_pred = regressor.predict(X_test)\nprint('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n\n# %% [code]\ndel train_df\ngc.collect(0)\n\n# %% [code]\niter_test = env.iter_test()\n\n# %% [code]\n\n\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df.loc[test_df['content_type_id'] == 0]\n    test_df = test_df.merge(user_answers_df, how='left', on='user_id')\n    test_df = test_df.merge(content_answers_df, how='left', on='content_id')\n    test_df['prior_question_had_explanation'] = test_df['prior_question_had_explanation'].fillna(value=False).astype(bool)\n    test_df.fillna(value = 0.5, inplace = True)\n\n\n    test_df['answered_correctly'] = regressor.predict(test_df[Xcol].to_numpy())\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n\n# %% [code]\nenv.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n\n# %% [code]\n",
         "execution_count":0,
         "outputs":[
            
         ]
      }
   ],
   "metadata":{
      "kernelspec":{
         "language":"python",
         "display_name":"Python 3",
         "name":"python3"
      },
      "language_info":{
         "pygments_lexer":"ipython3",
         "nbconvert_exporter":"python",
         "version":"3.6.4",
         "file_extension":".py",
         "codemirror_mode":{
            "name":"ipython",
            "version":3
         },
         "name":"python",
         "mimetype":"text/x-python"
      }
   },
   "nbformat":4,
   "nbformat_minor":4
}